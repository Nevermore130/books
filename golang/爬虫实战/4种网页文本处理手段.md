```shell
mkdir crawler

> cd crawler
> touch main.go
```

初始化项目的 go.mod 文件，module 名一般为远程 Git 仓库的名字：

```shell
go mod init  github.com/dreamerjackson/crawler
```

#### 抓取一个简单的网页

```go
package main

import (
  "fmt"
  "io/ioutil"
  "net/http"
)

func main() {
  url := "https://www.thepaper.cn/"
  resp, err := http.Get(url)

  if err != nil {
    fmt.Println("fetch url error:%v", err)
    return
  }

  defer resp.Body.Close()

  if resp.StatusCode != http.StatusOK {
    fmt.Printf("Error status code:%v", resp.StatusCode)
    return
  }

  body, err := ioutil.ReadAll(resp.Body)

  if err != nil {
    fmt.Println("read content failed:%v", err)
    return
  }

  fmt.Println("body:", string(body))
}
```

```
go run main.go > new.html
```



在标准库 strconv 包中，还包含很多字符串与其他类型进行转换的函数：

```go
// 字符串转换为十进制整数
func Atoi(s string) (int, error)
// 字符串转换为某一进制的整数，例如八进制、十六进制
func ParseInt(s string, base int, bitSize int) (i int64, err error)
// 整数转换为字符串
func Itoa(i int) string
// 某一进制的整数转换为字符串，例如八进制整数转换为字符串
func FormatInt(i int64, base int) string
```

#### 字符编码

要实现编码的通用性，我们使用官方处理字符集的库：

```
go get golang.org/x/net/html/charset
go get golang.org/x/text/encoding
```

Fetch 函数的代码如下所示，其获取网页的内容，检测网页的字符编码并将文本统一转换为 UTF-8 格式。

```go
// tag v0.0.4
func Fetch(url string) ([]byte, error) {

  resp, err := http.Get(url)

  if err != nil {
    panic(err)
  }

  defer resp.Body.Close()

  if resp.StatusCode != http.StatusOK {
    fmt.Printf("Error status code:%d", resp.StatusCode)
  }
  bodyReader := bufio.NewReader(resp.Body)
  e := DeterminEncoding(bodyReader)
  utf8Reader := transform.NewReader(bodyReader, e.NewDecoder())
  return ioutil.ReadAll(utf8Reader)
}

func DeterminEncoding(r *bufio.Reader) encoding.Encoding {

  bytes, err := r.Peek(1024)

  if err != nil {
    fmt.Println("fetch error:%v", err)
    return unicode.UTF8
  }

  e, _, _ := charset.DetermineEncoding(bytes, "")
  return e
}
```

如果返回的 HTML 文本小于 1024 字节，我们认为当前 HTML 文本有问题，直接返回默认的 UTF-8 编码就好了。DeterminEncoding 中核心的 charset.DetermineEncoding 函数用于检测并返回对应 HTML 文本的编码

### Xpath

之前获取卡片新闻的代码可以用 htmlquery 改写成下面的样子：

```go
// tag v0.0.6
func main() {
  url := "https://www.thepaper.cn/"
  body, err := Fetch(url)

  if err != nil {
    fmt.Println("read content failed:%v", err)
    return
  }
  doc, err := htmlquery.Parse(bytes.NewReader(body))
  if err != nil {
    fmt.Println("htmlquery.Parse failed:%v", err)
  }
  nodes := htmlquery.Find(doc, `//div[@class="news_li"]/h2/a[@target="_blank"]`)

  for _, node := range nodes {
    fmt.Println("fetch card ", node.FirstChild.Data)
  }
}
```

htmlquery.Parse 用于解析 HTML 文本，htmlquery.Find 则会通过 XPath 语法查找符合条件的节点

这串规则代表查找 target 属性为 _blank 的 a 标签，并且 a 节点的父节点为 h2 标签，h2 标签的父节点为 class 属性为 news_li 的 div 标签。

#### CSS 选择器

CSS 选择器考虑到了我们在搜索 HTML 文档时常用的属性。我们前面在 XPath 例子的中使用的 ``div[@class=“news_li”]``，在 CSS 选择器中可以简单地表示为 div.news_li。这是一种更加简单的表示方法

官方标准库中并不支持 CSS 选择器，我们在这里使用社区中知名的第三方库 (github.com/PuerkitoBio/goquery )，获取卡片新闻的代码如下：

```go
// tag v0.0.9
func main() {
  url := "https://www.thepaper.cn/"
  body, err := Fetch(url)

  if err != nil {
    fmt.Println("read content failed:%v", err)
    return
  }

  // 加载HTML文档
  doc, err := goquery.NewDocumentFromReader(bytes.NewReader(body))
  if err != nil {
    fmt.Println("read content failed:%v", err)
  }

  doc.Find("div.news_li h2 a[target=_blank]").Each(func(i int, s *goquery.Selection) {
    // 获取匹配标签中的文本
    title := s.Text()
    fmt.Printf("Review %d: %s\n", i, title)
  })
}
```



















