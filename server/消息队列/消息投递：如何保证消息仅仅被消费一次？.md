### 消息为什么会丢失 ###

如果要保证消息只被消费一次，首先就要保证消息不会丢失。那么消息从被写入到消息队列到被消费者消费完成，这个链路上会有哪些地方存在丢失消息的可能呢？其实主要存在三个场景：

* 消息从生产者写入到消息队列的过程；
* 消息在消息队列中的存储场景；
* 消息被消费者消费的过程。

#### 在消息生产的过程中丢失消息 ####

消息的生产者一般是我们的业务服务器，消息队列是独立部署在单独的服务器上的。两者之间的网络虽然是内网但是也会存在抖动的可能，而一旦发生抖动，消息就有可能因为网络的错误而丢失。

**采用的方案是消息重传。**也就是当你发现发送超时后就将消息重新发一次，但也不能无限制地重传消息。一般来说，如果不是消息队列发生故障或者是到消息队列的网络断开了，重试 2～3 次就可以了

不过这种方案可能会造成消息的重复，比方说消息生产时由于消息队列处理慢或者网络的抖动，导致虽然最终写入消息队列成功但在生产端却超时了，生产者重传这条消息就会形成重复的消息，针对上面的例子，直观显示在你面前的就会是你收到了两个现金红包。

#### 在消息队列中丢失消息 ####

拿 Kafka 举例，消息在 Kafka 中是存储在本地磁盘上的，而为了减少消息存储时对磁盘的随机 I/O，我们一般会**将消息先写入到操作系统的 Page Cache 中，然后再找合适的时机刷新到磁盘上。**

比如 Kafka 可以配置当达到某一时间间隔或者累积一定的消息数量的时候再刷盘，**也就是所说的异步刷盘。**

你可能会把刷盘的间隔设置很短或者设置累积一条消息就就刷盘，但这样频繁刷盘会对性能有比较大的影响，而且从经验来看，出现机器宕机或者掉电的几率也不高，所以不建议你这样做。

如果你的电商系统对消息丢失的容忍度很低，你可以**考虑以集群方式部署 Kafka 服务，通过部署多个副本备份数据保证消息尽量不丢失**

* Kafka 集群中有一个 Leader 负责消息的写入和消费，可以有多个 Follower 负责数据的备份
* Follower 中有一个特殊的集合叫做 ISR（in-sync replicas），当 Leader 故障时，新选举出来的 Leader 会从 ISR 中选择
* 默认 Leader 的数据会异步地复制给 Follower，这样在 Leader 发生掉电或者宕机时，Kafka 会从 Follower 中消费消息，减少消息丢失的可能

由于默认消息是异步地从 Leader 复制到 Follower 的，所以一旦 Leader 宕机，那些还没有来得及复制到 Follower 的消息还是会丢失。为了解决这个问题，Kafka 为生产者提供一个**选项叫做“acks”**，**当这个选项被设置为“all”时，生产者发送的每一条消息除了发给 Leader 外还会发给所有的 ISR，并且必须得到 Leader 和所有 ISR 的确认后才被认为发送成功。这样，只有 Leader 和所有的 ISR 都挂了消息才会丢失。**

1. 如果你需要确保消息一条都不能丢失，那么建议不要开启消息队列的同步刷盘，而是用集群的方式来解决，可以配置当所有 ISR Follower 都接收到消息才返回成功。
2.  如果对消息的丢失有一定的容忍度，那么建议不部署集群，即使以集群方式部署，也建议配置只发送给一个 Follower 就可以返回成功了。
3.  我们的业务系统一般对于消息的丢失有一定的容忍度，比如说以上面的红包系统为例，如果红包消息丢失了，我们只要后续给没有发送红包的用户补发红包就好了。

#### 在消费的过程中存在消息丢失的可能 ####

接收消息和处理消息的过程都可能会发生异常或者失败，比如消息接收时网络发生抖动，导致消息并没有被正确地接收到；处理消息时可能发生一些业务的异常导致处理流程未执行完成，这时如果更新消费进度，这条失败的消息就永远不会被处理了，也可以认为是丢失了

### 如何保证消息只被消费一次 ###

为了避免消息丢失我们需要付出两方面的代价：一方面是性能的损耗，一方面可能造成消息重复消费。

因为网络的抖动、机器的宕机和处理的异常都是比较难以避免的，在工业上并没有成熟的方法，因此我们会把要求放宽，只要保证即使消费到了重复的消息，**从消费的最终结果来看和只消费一次是等同的就好了，也就是保证在消息的生产和消费的过程是“幂等”的。**

#### 在生产、消费过程中增加消息幂等性的保证 ####

在消息生产过程中，在 Kafka0.11 版本和 Pulsar 中都支持“producer idempotency”的特性，翻译过来就是生产过程的幂等性

* 它的做法是给每一个生产者一个唯一的 ID，并且为生产的每一条消息赋予一个唯一 ID
* 消息队列的服务端会存储 < 生产者 ID，最后一条消息 ID> 的映射。
* 当某一个生产者产生新的消息时，消息队列服务端会比对消息 ID 是否与存储的最后一条 ID 一致，如果一致就认为是重复的消息，服务端会自动丢弃。

而在消费端，幂等性的保证会稍微复杂一些，你可以从通用层和业务层两个层面来考虑。

在通用层面，你可以在消息被生产的时候使用发号器给它生成一个全局唯一的消息 ID，**消息被处理之后把这个 ID 存储在数据库中，在处理下一条消息之前先从数据库里面查询这个全局 ID 是否被消费过，如果被消费过就放弃消费。**

无论是生产端的幂等性保证方式还是消费端通用的幂等性保证方式，**它们的共同特点都是为每一个消息生成一个唯一的 ID，然后在使用这个消息的时候，先比对这个 ID 是否已经存在**，如果存在则认为消息已经被使用过。所以这种方式是一种标准的实现幂等的方式

不过这样会有一个问题：如果消息在处理之后，**还没有来得及写入数据库，消费者宕机了重启之后发现数据库中并没有这条消息，还是会重复执行两次消费逻辑，这时你就需要引入事务机制**，保证消息处理和写入数据库必须同时成功或者同时失败，但是这样消息处理的成本就更高了，所以如果对于消息重复没有特别严格的要求，可以直接使用这种通用的方案，而不考虑引入事务。

**在业务层面怎么处理呢？**这里有很多种处理方式，其中有一种是增加乐观锁的方式。比如你的消息处理程序需要给一个人的账号加钱，那么你可以通过乐观锁的方式来解决。

* 具体的操作方式是这样的：你给每个人的账号数据中增加一个版本号的字段，在生产消息时先查询这个账户的版本号
* 并且将版本号连同消息一起发送给消息队列。消费端在拿到消息和版本号后，在执行更新账户金额 SQL 的时候带上版本号，类似于执行：

```sql
update user set amount = amount + 20, version=version+1 where userId=1 and version=1;
```

* 我们在更新数据时给数据加了乐观锁，这样在消费第一条消息时，version 值为 1，SQL 可以执行成功，并且同时把 version 值改为了 2；
* 在执行第二条相同的消息时，由于 version 值不再是 1，所以这条 SQL 不能执行成功，也就保证了消息的幂等性。















